#!/usr/bin/perl

use strict;
use warnings;

use Digest::MD5 qw(md5_hex);


# we don't want to create hashes for files larger than this.
# it takes a long time to generate MD5 sums of large files,
# so unless you need to check for duplicates on large files,
# 5M is a pretty good maximum.
my $MAXSIZE = 1024 * 1024 * 5;

main();

sub main {
    # use a unique delimeter for the size hash
    my $delimeter = chr(1);
    # which directory are we going to find dupes in? cwd if none provided
    my $dir       = $ARGV[0] || '.';
    # a hash containing delimited lists of files of the same file size
    # this should improve the lookup of same size files dramatically
    # key is filesize
    my %sizehash  = ();
    # hash of md5 hashes... get it, a hash of hashes...
    # key is filename
    my %hashhash  = ();
    # directory to move duplicates to, for saving, or confirming duplicity
    my $dupedir   = "$dir/.dupes";

    my $dupecount = scan_dir($dir,\%hashhash,\%sizehash,$dupedir);
  printf "%s duplicate files found\n", $dupecount;
}

sub scan_dir {
  my $dir       = shift;
  my $hashhash  = shift;
  my $sizehash  = shift;
  my $dupedir   = shift;

  my $dupes     = 0;

  if (opendir my $dir_fh, $dir) {
    foreach my $file (grep { !/^\..*$/ } readdir $dir_fh) {
      printf "$file\n";
      my $full = "$dir/$file";
      if (-d $full) {
        $dupes += scan_dir($full,$hashhash,$sizehash,$dupedir);
        next;
      }
      if (-f $full) {
        my $dupe = 0;
        my $size = (stat($full))[7];
        next if ($size > $MAXSIZE);
        my @sizematches = ();
           @sizematches = @{$$sizehash{$size}} if ($$sizehash{$size});
        foreach my $sizematch (@sizematches) {
          $$hashhash{$full} = sumfile($full) unless ($$hashhash{$full});
          $$hashhash{$sizematch} = sumfile($sizematch)
            unless $$hashhash{$sizematch};
          if ($$hashhash{$full} eq $$hashhash{$sizematch}) {
            $dupes++;
            mkdir $dupedir unless (-d $dupedir);
            if (rename $full,"$dupedir/$file") {
              printf "%s duplicates\n  %s\n", $full, $sizematch;
            } else {
              printf STDERR "failed to move duplicate %s\n", $full;
            }
            $dupe = 1;
            last;
          }
          # Only non-dupes or non-moved files should make it this far
        }
        push @sizematches, $full;
        $$sizehash{$size} = \@sizematches;
      }
    }
    closedir $dir_fh;
  } else {
    printf STDERR "Failed to open %s: %s\n", $dir, $!;
    exit 1;
  }
  return $dupes;
}


sub sumfile {
    my $file  = shift;

    my $md5   = '';

    if (open my $fh,'<',$file) {
      if (binmode $fh) {
        $md5 = md5_hex(<$fh>);
      } else {
        printf STDERR "Unable to binmode %s: %s\n", $file, $!;
        exit 2;
      }
      close $fh;
    } else {
      printf STDERR "Unable to open %s for reading: %s\n", $file, $!;
      exit 3;
    }
    return $md5;
}
